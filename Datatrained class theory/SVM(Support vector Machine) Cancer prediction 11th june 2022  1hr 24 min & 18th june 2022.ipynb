{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bebfb1e",
   "metadata": {},
   "source": [
    "# Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a33072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessory Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81363a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843786</th>\n",
       "      <td>M</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844359</th>\n",
       "      <td>M</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84458202</th>\n",
       "      <td>M</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844981</th>\n",
       "      <td>M</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84501001</th>\n",
       "      <td>M</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845636</th>\n",
       "      <td>M</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84610002</th>\n",
       "      <td>M</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846226</th>\n",
       "      <td>M</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846381</th>\n",
       "      <td>M</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84667401</th>\n",
       "      <td>M</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84799002</th>\n",
       "      <td>M</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>...</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848406</th>\n",
       "      <td>M</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84862001</th>\n",
       "      <td>M</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>...</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849014</th>\n",
       "      <td>M</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510426</th>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510653</th>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>...</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510824</th>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.02076</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511133</th>\n",
       "      <td>M</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>...</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851509</th>\n",
       "      <td>M</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.08632</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852552</th>\n",
       "      <td>M</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.09170</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>...</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                         \n",
       "842302           M       17.990         10.38          122.80     1001.0   \n",
       "842517           M       20.570         17.77          132.90     1326.0   \n",
       "84300903         M       19.690         21.25          130.00     1203.0   \n",
       "84348301         M       11.420         20.38           77.58      386.1   \n",
       "84358402         M       20.290         14.34          135.10     1297.0   \n",
       "843786           M       12.450         15.70           82.57      477.1   \n",
       "844359           M       18.250         19.98          119.60     1040.0   \n",
       "84458202         M       13.710         20.83           90.20      577.9   \n",
       "844981           M       13.000         21.82           87.50      519.8   \n",
       "84501001         M       12.460         24.04           83.97      475.9   \n",
       "845636           M       16.020         23.24          102.70      797.8   \n",
       "84610002         M       15.780         17.89          103.60      781.0   \n",
       "846226           M       19.170         24.80          132.40     1123.0   \n",
       "846381           M       15.850         23.95          103.70      782.7   \n",
       "84667401         M       13.730         22.61           93.60      578.3   \n",
       "84799002         M       14.540         27.54           96.73      658.8   \n",
       "848406           M       14.680         20.13           94.74      684.5   \n",
       "84862001         M       16.130         20.68          108.10      798.8   \n",
       "849014           M       19.810         22.15          130.00     1260.0   \n",
       "8510426          B       13.540         14.36           87.46      566.3   \n",
       "8510653          B       13.080         15.71           85.63      520.0   \n",
       "8510824          B        9.504         12.44           60.34      273.9   \n",
       "8511133          M       15.340         14.26          102.50      704.4   \n",
       "851509           M       21.160         23.04          137.20     1404.0   \n",
       "852552           M       16.650         21.38          110.00      904.6   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302            0.11840           0.27760         0.30010   \n",
       "842517            0.08474           0.07864         0.08690   \n",
       "84300903          0.10960           0.15990         0.19740   \n",
       "84348301          0.14250           0.28390         0.24140   \n",
       "84358402          0.10030           0.13280         0.19800   \n",
       "843786            0.12780           0.17000         0.15780   \n",
       "844359            0.09463           0.10900         0.11270   \n",
       "84458202          0.11890           0.16450         0.09366   \n",
       "844981            0.12730           0.19320         0.18590   \n",
       "84501001          0.11860           0.23960         0.22730   \n",
       "845636            0.08206           0.06669         0.03299   \n",
       "84610002          0.09710           0.12920         0.09954   \n",
       "846226            0.09740           0.24580         0.20650   \n",
       "846381            0.08401           0.10020         0.09938   \n",
       "84667401          0.11310           0.22930         0.21280   \n",
       "84799002          0.11390           0.15950         0.16390   \n",
       "848406            0.09867           0.07200         0.07395   \n",
       "84862001          0.11700           0.20220         0.17220   \n",
       "849014            0.09831           0.10270         0.14790   \n",
       "8510426           0.09779           0.08129         0.06664   \n",
       "8510653           0.10750           0.12700         0.04568   \n",
       "8510824           0.10240           0.06492         0.02956   \n",
       "8511133           0.10730           0.21350         0.20770   \n",
       "851509            0.09428           0.10220         0.10970   \n",
       "852552            0.11210           0.14570         0.15250   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  texture_worst  \\\n",
       "id                                            ...                  \n",
       "842302                0.14710         0.2419  ...          17.33   \n",
       "842517                0.07017         0.1812  ...          23.41   \n",
       "84300903              0.12790         0.2069  ...          25.53   \n",
       "84348301              0.10520         0.2597  ...          26.50   \n",
       "84358402              0.10430         0.1809  ...          16.67   \n",
       "843786                0.08089         0.2087  ...          23.75   \n",
       "844359                0.07400         0.1794  ...          27.66   \n",
       "84458202              0.05985         0.2196  ...          28.14   \n",
       "844981                0.09353         0.2350  ...          30.73   \n",
       "84501001              0.08543         0.2030  ...          40.68   \n",
       "845636                0.03323         0.1528  ...          33.88   \n",
       "84610002              0.06606         0.1842  ...          27.28   \n",
       "846226                0.11180         0.2397  ...          29.94   \n",
       "846381                0.05364         0.1847  ...          27.66   \n",
       "84667401              0.08025         0.2069  ...          32.01   \n",
       "84799002              0.07364         0.2303  ...          37.13   \n",
       "848406                0.05259         0.1586  ...          30.88   \n",
       "84862001              0.10280         0.2164  ...          31.48   \n",
       "849014                0.09498         0.1582  ...          30.88   \n",
       "8510426               0.04781         0.1885  ...          19.26   \n",
       "8510653               0.03110         0.1967  ...          20.49   \n",
       "8510824               0.02076         0.1815  ...          15.66   \n",
       "8511133               0.09756         0.2521  ...          19.08   \n",
       "851509                0.08632         0.1769  ...          35.59   \n",
       "852552                0.09170         0.1995  ...          31.56   \n",
       "\n",
       "          perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                           \n",
       "842302             184.60      2019.0            0.1622             0.6656   \n",
       "842517             158.80      1956.0            0.1238             0.1866   \n",
       "84300903           152.50      1709.0            0.1444             0.4245   \n",
       "84348301            98.87       567.7            0.2098             0.8663   \n",
       "84358402           152.20      1575.0            0.1374             0.2050   \n",
       "843786             103.40       741.6            0.1791             0.5249   \n",
       "844359             153.20      1606.0            0.1442             0.2576   \n",
       "84458202           110.60       897.0            0.1654             0.3682   \n",
       "844981             106.20       739.3            0.1703             0.5401   \n",
       "84501001            97.65       711.4            0.1853             1.0580   \n",
       "845636             123.80      1150.0            0.1181             0.1551   \n",
       "84610002           136.50      1299.0            0.1396             0.5609   \n",
       "846226             151.70      1332.0            0.1037             0.3903   \n",
       "846381             112.00       876.5            0.1131             0.1924   \n",
       "84667401           108.80       697.7            0.1651             0.7725   \n",
       "84799002           124.10       943.2            0.1678             0.6577   \n",
       "848406             123.40      1138.0            0.1464             0.1871   \n",
       "84862001           136.80      1315.0            0.1789             0.4233   \n",
       "849014             186.80      2398.0            0.1512             0.3150   \n",
       "8510426             99.70       711.2            0.1440             0.1773   \n",
       "8510653             96.09       630.5            0.1312             0.2776   \n",
       "8510824             65.13       314.9            0.1324             0.1148   \n",
       "8511133            125.10       980.9            0.1390             0.5954   \n",
       "851509             188.00      2615.0            0.1401             0.2600   \n",
       "852552             177.00      2215.0            0.1805             0.3578   \n",
       "\n",
       "          concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                                \n",
       "842302            0.71190               0.26540          0.4601   \n",
       "842517            0.24160               0.18600          0.2750   \n",
       "84300903          0.45040               0.24300          0.3613   \n",
       "84348301          0.68690               0.25750          0.6638   \n",
       "84358402          0.40000               0.16250          0.2364   \n",
       "843786            0.53550               0.17410          0.3985   \n",
       "844359            0.37840               0.19320          0.3063   \n",
       "84458202          0.26780               0.15560          0.3196   \n",
       "844981            0.53900               0.20600          0.4378   \n",
       "84501001          1.10500               0.22100          0.4366   \n",
       "845636            0.14590               0.09975          0.2948   \n",
       "84610002          0.39650               0.18100          0.3792   \n",
       "846226            0.36390               0.17670          0.3176   \n",
       "846381            0.23220               0.11190          0.2809   \n",
       "84667401          0.69430               0.22080          0.3596   \n",
       "84799002          0.70260               0.17120          0.4218   \n",
       "848406            0.29140               0.16090          0.3029   \n",
       "84862001          0.47840               0.20730          0.3706   \n",
       "849014            0.53720               0.23880          0.2768   \n",
       "8510426           0.23900               0.12880          0.2977   \n",
       "8510653           0.18900               0.07283          0.3184   \n",
       "8510824           0.08867               0.06227          0.2450   \n",
       "8511133           0.63050               0.23930          0.4667   \n",
       "851509            0.31550               0.20090          0.2822   \n",
       "852552            0.46950               0.20950          0.3613   \n",
       "\n",
       "          fractal_dimension_worst  Unnamed: 32  \n",
       "id                                              \n",
       "842302                    0.11890          NaN  \n",
       "842517                    0.08902          NaN  \n",
       "84300903                  0.08758          NaN  \n",
       "84348301                  0.17300          NaN  \n",
       "84358402                  0.07678          NaN  \n",
       "843786                    0.12440          NaN  \n",
       "844359                    0.08368          NaN  \n",
       "84458202                  0.11510          NaN  \n",
       "844981                    0.10720          NaN  \n",
       "84501001                  0.20750          NaN  \n",
       "845636                    0.08452          NaN  \n",
       "84610002                  0.10480          NaN  \n",
       "846226                    0.10230          NaN  \n",
       "846381                    0.06287          NaN  \n",
       "84667401                  0.14310          NaN  \n",
       "84799002                  0.13410          NaN  \n",
       "848406                    0.08216          NaN  \n",
       "84862001                  0.11420          NaN  \n",
       "849014                    0.07615          NaN  \n",
       "8510426                   0.07259          NaN  \n",
       "8510653                   0.08183          NaN  \n",
       "8510824                   0.07773          NaN  \n",
       "8511133                   0.09946          NaN  \n",
       "851509                    0.07526          NaN  \n",
       "852552                    0.09564          NaN  \n",
       "\n",
       "[25 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the CSV data here and print head\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/training-ml/Files/main/breast%20cancer.csv',index_col=0)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b6ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape     -------------> (569, 32)\n",
      "Each column and data type and its count \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 569 entries, 842302 to 92751\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    object \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      " 31  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), object(1)\n",
      "memory usage: 146.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#print summary\n",
    "print('shape     ------------->',df.shape)\n",
    "print('Each column and data type and its count','\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec8465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP ALERT 1 : Unnamed :32 column has all nulls.safe to remove the column.\n",
    "df=df.drop(['Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8928a2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f8487a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82cfd1",
   "metadata": {},
   "source": [
    "seems no other cols have nulls. It's safe to poceed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8e95d",
   "metadata": {},
   "source": [
    "As we can see each feature data scaled differently. Let's go ahead and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00802427",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "x=df.drop('diagnosis',axis=1)\n",
    "x_scaled=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72845bc9",
   "metadata": {},
   "source": [
    "# Principal component Analysis  (PCA)\n",
    "\n",
    "PCA is dimension reduction technique (Not feature selection technique)\n",
    "\n",
    "PCA can be applied only on Features (not on target)\n",
    "\n",
    "PCA  can be applied when you have too many features and their correlation is not that significant with target.\n",
    "\n",
    "PCA will also takes care of multicollinearity problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e4d7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19283683e+00,  1.94858307e+00, -1.12316616e+00, ...,\n",
       "        -3.39144536e-02,  4.56477199e-02, -4.71692081e-02],\n",
       "       [ 2.38780180e+00, -3.76817174e+00, -5.29292687e-01, ...,\n",
       "         3.26241827e-02, -5.68742432e-03, -1.86787626e-03],\n",
       "       [ 5.73389628e+00, -1.07517380e+00, -5.51747593e-01, ...,\n",
       "         4.70258247e-02,  3.14589659e-03,  7.50534755e-04],\n",
       "       ...,\n",
       "       [ 1.25617928e+00, -1.90229671e+00,  5.62730526e-01, ...,\n",
       "        -2.57775589e-03,  6.70621179e-03,  3.77041667e-03],\n",
       "       [ 1.03747941e+01,  1.67201011e+00, -1.87702933e+00, ...,\n",
       "        -6.80863833e-02, -8.41632764e-02, -2.37828222e-02],\n",
       "       [-5.47524330e+00, -6.70636791e-01,  1.49044308e+00, ...,\n",
       "        -9.51587894e-03, -6.09131090e-02, -1.94755854e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA()\n",
    "pca.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1958611f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Let's plot scree plot to check the best component\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c0a36",
   "metadata": {},
   "source": [
    "Around 13 Principal components are able to explain >95% variance. Its safe to consider starting 13 PC's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bc24c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411424</td>\n",
       "      <td>2.159370</td>\n",
       "      <td>-0.398406</td>\n",
       "      <td>-0.157119</td>\n",
       "      <td>-0.877402</td>\n",
       "      <td>0.262950</td>\n",
       "      <td>-0.859012</td>\n",
       "      <td>0.103397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.240991</td>\n",
       "      <td>-0.711904</td>\n",
       "      <td>1.106996</td>\n",
       "      <td>0.813120</td>\n",
       "      <td>0.157929</td>\n",
       "      <td>-0.943537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>0.541452</td>\n",
       "      <td>-0.668166</td>\n",
       "      <td>0.097372</td>\n",
       "      <td>0.024066</td>\n",
       "      <td>0.454275</td>\n",
       "      <td>-0.605600</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>-0.410631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960878</td>\n",
       "      <td>3.053422</td>\n",
       "      <td>1.429911</td>\n",
       "      <td>1.059566</td>\n",
       "      <td>-1.405438</td>\n",
       "      <td>-1.116974</td>\n",
       "      <td>-1.151507</td>\n",
       "      <td>1.011317</td>\n",
       "      <td>-0.933286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546747</td>\n",
       "      <td>-1.226495</td>\n",
       "      <td>-0.936213</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>-0.263806</td>\n",
       "      <td>0.377704</td>\n",
       "      <td>0.651359</td>\n",
       "      <td>-0.110516</td>\n",
       "      <td>0.387949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "      <td>-2.375193</td>\n",
       "      <td>-0.596130</td>\n",
       "      <td>-0.035472</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>0.256988</td>\n",
       "      <td>-0.062648</td>\n",
       "      <td>0.123338</td>\n",
       "      <td>-0.051726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510723</td>\n",
       "      <td>-0.246710</td>\n",
       "      <td>-0.716326</td>\n",
       "      <td>-1.113359</td>\n",
       "      <td>-0.105207</td>\n",
       "      <td>-0.108632</td>\n",
       "      <td>0.244806</td>\n",
       "      <td>0.222754</td>\n",
       "      <td>-0.192644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534447</td>\n",
       "      <td>-0.192758</td>\n",
       "      <td>0.341887</td>\n",
       "      <td>0.393916</td>\n",
       "      <td>0.520877</td>\n",
       "      <td>-0.840514</td>\n",
       "      <td>0.096474</td>\n",
       "      <td>0.157422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.223081</td>\n",
       "      <td>-0.280243</td>\n",
       "      <td>-0.542037</td>\n",
       "      <td>-0.089299</td>\n",
       "      <td>-0.178636</td>\n",
       "      <td>-0.697472</td>\n",
       "      <td>1.225224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184703</td>\n",
       "      <td>1.617837</td>\n",
       "      <td>1.698952</td>\n",
       "      <td>1.046354</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>-0.047725</td>\n",
       "      <td>-0.144095</td>\n",
       "      <td>-0.179496</td>\n",
       "      <td>0.678898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1        PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0     9.192837   1.948583 -1.123166  3.633731 -1.195110  1.411424  2.159370   \n",
       "1     2.387802  -3.768172 -0.529293  1.118264  0.621775  0.028656  0.013358   \n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177086  0.541452 -0.668166   \n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960878  3.053422  1.429911   \n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546747 -1.226495 -0.936213   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074824 -2.375193 -0.596130   \n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510723 -0.246710 -0.716326   \n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534447 -0.192758   \n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033742  0.567936  0.223081   \n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184703  1.617837  1.698952   \n",
       "\n",
       "          PC8       PC9      PC10      PC11      PC12      PC13  \n",
       "0   -0.398406 -0.157119 -0.877402  0.262950 -0.859012  0.103397  \n",
       "1    0.240991 -0.711904  1.106996  0.813120  0.157929 -0.943537  \n",
       "2    0.097372  0.024066  0.454275 -0.605600  0.124383 -0.410631  \n",
       "3    1.059566 -1.405438 -1.116974 -1.151507  1.011317 -0.933286  \n",
       "4    0.636376 -0.263806  0.377704  0.651359 -0.110516  0.387949  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "564 -0.035472  0.987930  0.256988 -0.062648  0.123338 -0.051726  \n",
       "565 -1.113359 -0.105207 -0.108632  0.244806  0.222754 -0.192644  \n",
       "566  0.341887  0.393916  0.520877 -0.840514  0.096474  0.157422  \n",
       "567 -0.280243 -0.542037 -0.089299 -0.178636 -0.697472  1.225224  \n",
       "568  1.046354  0.374101 -0.047725 -0.144095 -0.179496  0.678898  \n",
       "\n",
       "[569 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=13)\n",
    "new_pcomp=pca.fit_transform(x_scaled)\n",
    "princi_comp=pd.DataFrame(new_pcomp,columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13'])\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e026fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace label column (diagnosis) into binary codes\n",
    "df['diagnosis']=df['diagnosis'].replace({'M':1,'B':0})\n",
    "y=df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd61ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split into train and test\n",
    "x_train,x_test,y_train,y_test=train_test_split(princi_comp,y,test_size=0.25,random_state=355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc646c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf,x_train,x_test,y_tain,y_test,train=True):\n",
    "    if train:\n",
    "        y_pred=clf.predict(x_train)\n",
    "        \n",
    "        print(\"\\n===============Train Result======================\")\n",
    "        \n",
    "        print(f\"Accuracy score:{accuracy_score(y_train,y_pred)* 100:.2f}%\")\n",
    "        \n",
    "        \n",
    "    elif train==False:\n",
    "        pred=clf.predict(x_test)\n",
    "        \n",
    "        print('\\n===================Test Result=================================')\n",
    "        print(f\"Accuracy score:{accuracy_score(y_test,pred)*100:.2f}%\")\n",
    "        \n",
    "        print('\\n \\n Test classification Report \\n' ,classification_report(y_test,pred,digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f130c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============Train Result======================\n",
      "Accuracy score:98.12%\n",
      "\n",
      "===================Test Result=================================\n",
      "Accuracy score:97.90%\n",
      "\n",
      " \n",
      " Test classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        93\n",
      "           1       1.00      0.94      0.97        50\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "#svc model training and printing train and test score\n",
    "svc.fit(x_train,y_train)\n",
    "# call the function and pass dataset to check train and test score\n",
    "\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=True)\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ddbee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============Train Result======================\n",
      "Accuracy score:100.00%\n",
      "\n",
      "===================Test Result=================================\n",
      "Accuracy score:94.41%\n",
      "\n",
      " \n",
      " Test classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        93\n",
      "           1       0.94      0.90      0.92        50\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.93      0.94       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt=GradientBoostingClassifier()\n",
    "#GBDT model training and printing train and test score\n",
    "gbdt.fit(x_train,y_train)\n",
    "\n",
    "# call the function and pass dataset to check train and test score\n",
    "print_score(gbdt,x_train,x_test,y_train,y_test,train=True)\n",
    "print_score(gbdt,x_train,x_test,y_train,y_test,train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdc6772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============Train Result======================\n",
      "Accuracy score:100.00%\n",
      "\n",
      "===================Test Result=================================\n",
      "Accuracy score:96.50%\n",
      "\n",
      " \n",
      " Test classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        93\n",
      "           1       0.94      0.96      0.95        50\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#Random Forest model training and printing train and test score\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "# call the function and pass dataset to check train and test score\n",
    "print_score(rf,x_train,x_test,y_train,y_test,train=True)\n",
    "print_score(rf,x_train,x_test,y_train,y_test,train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e93a6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fdd6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C     = It is a hypermeter in SVM to cntrol error. How much error we can allow.\n",
    "#         Low C means allowing less number of error/s and\n",
    "#          Large C means allowing more nuber of errors.\n",
    "\n",
    "# gamma =Gamma decides that how much curvature we want in a decision boundary.Gamma high means more curvature.\n",
    "#        Gamma Low means Less curvature.\n",
    "\n",
    "param_grid={'C' : [1,5,10,20],\n",
    "           'gamma': [0.001,0.01,0.02,0.002]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc560901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'gamma': 0.01}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch=GridSearchCV(svc,param_grid)\n",
    "gridsearch.fit(x_train,y_train)\n",
    "\n",
    "# best parms\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b3e4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============Train Result======================\n",
      "Accuracy score:97.65%\n",
      "\n",
      "===================Test Result=================================\n",
      "Accuracy score:97.90%\n",
      "\n",
      " \n",
      " Test classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        93\n",
      "           1       1.00      0.94      0.97        50\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC Model Training and printing train and test score(post param update)\n",
    "\n",
    "svc = SVC(C= 7, gamma =0.001)\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "#Call the function and pass dataset to check train and test score\n",
    "\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=True)\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428b4fb",
   "metadata": {},
   "source": [
    "# Creating Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9b008",
   "metadata": {},
   "source": [
    "In real world the final model is built with popeline. We work on all preprocessing steps, do EDA, make analysis etc.Once we find all the hyperparameter and feature selection techniquesetc, we use the main techniques and create pipeline.This will be clean and better flow of data through series of sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "603ff4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7a3f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('https://raw.githubusercontent.com/training-ml/Files/main/breast%20cancer.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3798d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Unnamed: 32','diagnosis'],axis=1)\n",
    "y=df.diagnosis\n",
    "x_train,x_test,y_train,y_test=train_test_split(\n",
    "x,y,test_size=0.25,random_state=355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da54297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('Scaler',StandardScaler()),    # fit_transform\n",
    "              ('PCA' ,PCA(n_components=13)),    # fit_transform\n",
    "              ('SVM',SVC(C=7,gamma=0.01))])    # ONLY fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d0aec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA(n_components=13)),\n",
       "                (&#x27;SVM&#x27;, SVC(C=7, gamma=0.01))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA(n_components=13)),\n",
       "                (&#x27;SVM&#x27;, SVC(C=7, gamma=0.01))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=13)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=7, gamma=0.01)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Scaler', StandardScaler()), ('PCA', PCA(n_components=13)),\n",
       "                ('SVM', SVC(C=7, gamma=0.01))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f81c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe0e2f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8c63b",
   "metadata": {},
   "source": [
    "* key points\n",
    ". you need to know the execution sequence(example- Imputation techniques should be applied before standard scaler and then PCA\n",
    "\n",
    ". you cannot use pipeline for plotting graphs and analysis.\n",
    "\n",
    ". Analysis can be done before creating a pipeline\n",
    "\n",
    ". Do not use unnecessary methods in the pipeline\n",
    "\n",
    " you can also use ny encoding/imputation techniques in the pipeline like.\n",
    " \n",
    " .('Simple Imputer',SinpleImputer(strategy='mean')),#fit_transform\n",
    " \n",
    " .('Ohe',OneHotEncoder(handle_unknown='ignore')), #fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ba363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
